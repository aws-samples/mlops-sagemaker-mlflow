{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5845c0a-25c6-40e6-a3ba-2b3316bd38c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#Â Step 4: Add a deployment pipeline\n",
    "In previous four steps you implemented an automated data processing and model building pipeline. Each run of the pipeline produces a new version of the model. This notebook implements the automated model deployment step in our ML workflow.\n",
    "\n",
    "![](img/sagemaker-mlops-project-deploy-diagram.jpg)\n",
    "\n",
    "You can use a [SageMaker MLOps project template](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-templates.html) to provision a ready-to use model deployment CI/CD pipeline.\n",
    "\n",
    "This template automates the deployment of models in the SageMaker model registry to SageMaker endpoints for real-time inference. This template recognizes changes in the model registry. When a new model version is registered and approved, it automatically initiates a deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46ca98f-099f-4f24-8e24-67bdc86d8fc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\"> Make sure you using <code>Python 3</code> kernel in JupyterLab for this notebook.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f78f266-83a4-4172-b1ff-a6bc4712e587",
   "metadata": {},
   "source": [
    "First, we need to install the python dependencies for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58245af4-266c-4c4e-a1e7-a760f2208eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install jsonlines tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd36377-d862-4d18-a575-860bf0c15b31",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker \n",
    "from time import gmtime, strftime, sleep\n",
    "import json\n",
    "import os\n",
    "from sagemaker.predictor import Predictor\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a760443-7627-4029-b01e-2b0f1056566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d0d80-e858-42d2-84c2-35140c9a3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b3db4e-4a75-43f3-ab98-96edcd45ac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(model_package_group_name) > 0\n",
    "assert len(region) > 0\n",
    "assert len(bucket_name) > 0\n",
    "assert len(bucket_prefix) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb83a8-521f-4405-bb4f-eee77ab56094",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm = boto3.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e91bef-93a8-4265-ad0c-d6f72fde9099",
   "metadata": {},
   "source": [
    "## Create an MLOps project\n",
    "Follow the same procedure as in the step 4 notebook to create a model deployment MLOps project. \n",
    "\n",
    "Option 1 is recommended as it requires no manual input and has no dependency on the UX.</br>\n",
    "Option 2 is given to demonstrate [**Create Project** UI flow](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-create.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8f3124-56f3-4d5a-b354-9e7930ba1c4d",
   "metadata": {},
   "source": [
    "### Option 1: Create project programmatically\n",
    "Use `boto3` to create an MLOps project via a SageMaker API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f268b-1dbe-40f9-884a-7ce63f7d1352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc = boto3.client(\"servicecatalog\")\n",
    "\n",
    "sc_provider_name = \"Amazon SageMaker\"\n",
    "sc_product_name = \"MLOps template for model deployment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb4137-e7c7-447e-9f87-2012963ea2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_ids = [p['ProductId'] for p in sc.search_products(\n",
    "    Filters={\n",
    "        'FullTextSearch': [sc_product_name]\n",
    "    },\n",
    ")['ProductViewSummaries'] if p[\"Name\"]==sc_product_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8ca253-eca3-4de2-9d8a-7dcfd8dc1c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3c3f09-ca7d-43de-9432-c106f32d0c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you get any exception from this code, go to the Option 2 and create a project in Studio UI\n",
    "if not len(p_ids):\n",
    "    raise Exception(\"No Amazon SageMaker ML Ops products found!\")\n",
    "elif len(p_ids) > 1:\n",
    "    raise Exception(\"Too many matching Amazon SageMaker ML Ops products found!\")\n",
    "else:\n",
    "    product_id = p_ids[0]\n",
    "    print(f\"ML Ops product id: {product_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38294903-3f86-4a3a-9849-40af57753c34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "provisioning_artifact_id = sorted(\n",
    "    [i for i in sc.list_provisioning_artifacts(\n",
    "        ProductId=product_id\n",
    "    )['ProvisioningArtifactDetails'] if i['Guidance']=='DEFAULT'],\n",
    "    key=lambda d: d['Name'], reverse=True)[0]['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b48d04-b558-4727-8e1f-1ac6b38dc7a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "provisioning_artifact_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae543a2-a20e-40e2-b251-c87462be9507",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_name = f\"model-deploy-{strftime('%-m-%d-%H-%M-%S', gmtime())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee8a72b-53d3-461a-95d4-6af781d7ce44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_parameters = [\n",
    "    {\n",
    "        'Key': 'SourceModelPackageGroupName',\n",
    "        'Value': model_package_group_name\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fef1a7-0396-4501-85c6-18ad874cabb9",
   "metadata": {},
   "source": [
    "Finally, create a SageMaker project from the service catalog product template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf05f97-ad6a-4503-9e47-b220f257cb58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create SageMaker project\n",
    "r = sm.create_project(\n",
    "    ProjectName=project_name,\n",
    "    ProjectDescription=\"Model build project\",\n",
    "    ServiceCatalogProvisioningDetails={\n",
    "        'ProductId': product_id,\n",
    "        'ProvisioningArtifactId': provisioning_artifact_id,\n",
    "        'ProvisioningParameters': project_parameters\n",
    "    },\n",
    ")\n",
    "\n",
    "print(r)\n",
    "project_id = r[\"ProjectId\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2e65a3-0185-4b33-b8b4-f3db9689dab8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Wait until project creation is completed by running the next cell</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9058fa5",
   "metadata": {},
   "source": [
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi48L3RleHQ+Cjwvc3ZnPgo=\" alt=\"Time alert open medium\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7537e2-e377-48d1-a246-0c5f1083d519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Project creation takes about 3-5 min\n",
    "while sm.describe_project(ProjectName=project_name)['ProjectStatus'] != 'CreateCompleted':\n",
    "    sleep(10)\n",
    "    print(\"Waiting for project creation completion\")\n",
    "\n",
    "print(f\"MLOps project {project_name} creation completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9981b62",
   "metadata": {},
   "source": [
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a65ed90-e50d-49ca-b58c-1e567bc60749",
   "metadata": {},
   "source": [
    "### End of Option 1: Create project programmatically\n",
    "Now you have provisioned a project template in your SageMaker environment. Navigate to the section **Working with MLOps project for model deployment**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9545f6-e793-41be-ae2c-9223fe8f6fb8",
   "metadata": {},
   "source": [
    "### Option 2: Create a project in Studio UI\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Skip this section if you created a project programmatically </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd48069-90a9-4bc7-a3d5-ae030f2299d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The last used model package group is {model_package_group_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d43237-6357-48ca-8e86-c3babc30011c",
   "metadata": {},
   "source": [
    "Follow the instructions in the Developer Guide â€“ [Create a MLOps Project using Amazon SageMaker Studio or Studio Classic](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-create.html). Choose the **Studio** option.\n",
    "\n",
    "For the template choose the **Model deployment**.\n",
    "In the **Project details** you need to provide a name and an optional project description. \n",
    "\n",
    "This template has a required parameter `SourceModelPackageGroupName`. Put the model package group name you used in the step 3 and 4 notebooks.\n",
    "\n",
    "Optionally, add tags, which are key-value pairs that you can use to track your projects.\n",
    "\n",
    "Choose **Create** and wait for the project to appear in the Projects list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711f29d3-97d5-44ce-a519-b23c1e36a386",
   "metadata": {},
   "source": [
    "###Â End of Option 2: Create a project in Studio UI\n",
    "Now when you have the project created, move to the section **Working with MLOps project for model deployment**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceddf72-4a24-447d-9718-d940a3b54252",
   "metadata": {},
   "source": [
    "## Working with MLOps project for model deployment\n",
    "The template provisions a CodeCommit repository with configuration files to specify the model deployment steps, AWS CloudFormation templates to define endpoints as infrastructure, and seed code for testing the endpoint.\n",
    "\n",
    "This template provides the following resources:\n",
    "\n",
    "1. An AWS CodeCommit repository that contains template code that deploys models to endpoints in staging and production environments\n",
    "2. An AWS CodePipeline pipeline that has `source`, `build`, `deploy-to-staging`, and `deploy-to-production` steps. The `source` step points to the CodeCommit repository, and the `build` step gets the code from that repository and generates CloudFormation stacks to deploy. The `deploy-to-staging` and `deploy-to-production` steps deploy the CloudFormation stacks to their respective environments. There is a manual approval step between the staging and production build steps, so that a MLOps engineer must approve the model before it is deployed to production.\n",
    "3. An Amazon EventBridge rule to launch a CodePipeline pipeline execution when a model package version is approved or rejected.\n",
    "4. There is also a manual approval step after the placeholder unit tests. You can implement your own tests to replace the placeholders tests.\n",
    "\n",
    "The template also deploys an Amazon S3 bucket to store artifacts, including CodePipeline and CodeBuild artifacts, and any artifacts generated from the SageMaker pipeline runs.\n",
    "\n",
    "The following diagram shows the architecture.\n",
    "\n",
    "<img src=\"img/mlops-model-deploy.png\" width=\"600\"/>\n",
    "\n",
    "You don't need to implement any configuration changes for the project. The model deployment pipeline works out of the box.\n",
    "To start the model deployment pipeline, you must approve the model version in the model registry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64405ac3-aefa-4ba9-aa8a-f7fca4a78009",
   "metadata": {},
   "source": [
    "### Approve a model version\n",
    "Approving a model version causes the MLOps project to launch the model deployment process. \n",
    "\n",
    "In the first step, the model deployment pipeline deploys the model version to a staging SageMaker real-time inference end-point.\n",
    "\n",
    "You can approve the model version either in Studio in the Model registry or do it programmatically in the notebook. Let's do it programatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13610b3-be77-4a2e-abe9-bc0d55acf082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print(model_package_group_name)\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"Run the step 03 notebook to create a pipeline, run the pipeline, and register a model version in the model registry\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639e8925-5e0d-4911-a087-a026b3b1a21f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list all model packages and select the latest one\n",
    "model_packages = []\n",
    "\n",
    "for p in sm.get_paginator('list_model_packages').paginate(\n",
    "        ModelPackageGroupName=model_package_group_name,\n",
    "        SortBy=\"CreationTime\",\n",
    "        SortOrder=\"Descending\",\n",
    "    ):\n",
    "    model_packages.extend(p[\"ModelPackageSummaryList\"])\n",
    "\n",
    "if len(model_packages) == 0:\n",
    "    raise Exception(f\"No model package is found for {model_package_group_name} model package group. Run a model creation pipeline first.\")\n",
    "\n",
    "print(f\"There are {len(model_packages)} model versions in the {model_package_group_name} model package group\")\n",
    "print(f\"Approve the most recent model package:\")\n",
    "\n",
    "latest_model_package_arn = model_packages[0][\"ModelPackageArn\"]\n",
    "print(latest_model_package_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e69876-c48e-441a-adb1-94f37f3c3cc5",
   "metadata": {},
   "source": [
    "The following statement sets the `ModelApprovalStatus` for the most recent model package in the model registry to `Approved`. The model package state change launches the EventBridge rule and the rule launches the CodePipeline CI/CD pipeline with model deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef387cb-c889-4e58-a52a-8c7def24836d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_package_update_response = sm.update_model_package(\n",
    "    ModelPackageArn=latest_model_package_arn,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451a3532-845c-4697-b059-330735da6dfd",
   "metadata": {},
   "source": [
    "You can see the last model version in the model registry in the Studio UI changed the **Status** to `Approved`:\n",
    "\n",
    "![](img/model-package-group-version-approval.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca217b12-d020-4eb3-820a-de6431f4e82d",
   "metadata": {},
   "source": [
    "### Deployment pipeline execution\n",
    "Upon approval of a model version in the code cell above, the model deployment CI/CD pipeline performs the following actions:\n",
    "1. Create CloudFormation parameter configuration files with stating and prod parameters for CloudFormation templates with SageMaker endpoint IaC\n",
    "1. Create a SageMaker real-time inference endpoint with the name `<PROJECT-NAME>-staging` in the current account\n",
    "1. Run the test script on the staging endpoint\n",
    "1. Wait until the test result is manually approved in [AWS CodePipeline console](https://console.aws.amazon.com/codesuite/codepipeline)\n",
    "1. Create a SageMaker endpoint with the name `<PROJECT-NAME>-prod` in the current account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3956a712-c8d6-4093-b9d0-e3a5cce443d8",
   "metadata": {},
   "source": [
    "Wait about 10-15 minutes until the pipeline finishes deployment of the staging endpoint. You can see the status of the endpoint in the Studio UI in **Deployments** > **Endpoints**:\n",
    "\n",
    "![](img/sagemaker-mlops-deploy-endpoint-status.jpg)\n",
    "\n",
    "After the endpoint status changed from `Creating` to `InService`, the staging endpoint is fully operational. You can launch the model deployment process to the production stage by manually approving the **DeployStaging** stage of the CodePipeline pipeline. In the next section you approve the model deployment and launch the second stage of the deployment into a production endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb513c-8171-4c8f-9769-7cae2efbf42a",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <p style=\" text-align: center; margin: auto;\">Wait until staging endpoint status changes to InService, then continue with the following code cells.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a955a06c-1ce7-40d8-84a6-a0c522da288e",
   "metadata": {},
   "source": [
    "# Testing the SageMaker endpoint\n",
    "After a successful deployment to a SageMaker endpoint in staging, let's verify the endpoint by running some inferences through it.\n",
    "When it comes to serving your model in an endpoint, Sagemaker offers many different options:\n",
    "\n",
    "## SageMaker Endpoint\n",
    "SageMaker provides different options for your inference use cases, giving you choice over the technical breadth and depth of your deployments:\n",
    "\n",
    "* **Deploying a model to an endpoint.** When deploying your model, consider the following options:\n",
    "   + [Real-time inference](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html). Real-time inference is ideal for inference workloads where you have interactive, low latency requirements.\n",
    "   + [Deploy models with Amazon SageMaker Serverless Inference](https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html). Use Serverless Inference to deploy models without configuring or managing any of the underlying infrastructure. This option is ideal for workloads which have idle periods between traffic spurts and can tolerate cold starts.\n",
    "   + [Asynchronous inference](https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference.html). queues incoming requests and processes them asynchronously. This option is ideal for requests with large payload sizes (up to 1GB), long processing times (up toAsynchronous Inference one hour), and near real-time latency requirements\n",
    "\n",
    "* **Cost optimization**. To optimize your inference costs, consider the following options:\n",
    "\n",
    "   + [Automatically Scale Amazon SageMaker Models](https://docs.aws.amazon.com/sagemaker/latest/dg/endpoint-auto-scaling.html). Use autoscaling to dynamically adjust the compute resources for your endpoints based on incoming traffic patterns, which helps you optimize costs by only paying for the resources you're using at a given time.\n",
    " \n",
    "The following diagram provides an overview of all the deployment options in SageMaker:\n",
    "\n",
    "![](img/sagemaker-deployment-modes.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c7834-e18e-41a6-ba57-d4b4077f9a08",
   "metadata": {},
   "source": [
    "## Real time Inference from a SageMaker endpoint\n",
    "To demonstrate the inference capabilities, we'll explore both realtime and batch transform in this notebook. We'll use the staging endpoint for our test so that we know the endpoint works as expected before deploying to production environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fbfe83-b385-4f9c-bc13-8bea5a8050dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all deployed real-time endpoints. Depending on your existing environment you might have multiple endpoints\n",
    "endpoints = sm.list_endpoints(StatusEquals=\"InService\")[\"Endpoints\"]\n",
    "endpoint_name = \"\"\n",
    "\n",
    "if not len(endpoints):\n",
    "    print(f\"There is no deployed active endpoints. You must have at least one endpoint. Run the previous cell in this notebook to deploy an endpoint\")\n",
    "else:\n",
    "    endpoint_name = endpoints[0]['EndpointName']\n",
    "    print(f\"There are {len(endpoints)} active inference endpoints.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99736857-8e8b-4826-afa8-0cc3dcbd671e",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> If you are running this workshop as an instructor led training, the `endpoint_name` is set for you so there is nothing for you to do. Otherwise, simply update the endpoint_name with the appropriate endpoint_name for the test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6afc2d-7dfa-4b90-ac30-851f1f09d946",
   "metadata": {},
   "source": [
    "###Â Define helper functions\n",
    "Define some helper functions with code snippets that you're going to use throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37f768a-6acb-411f-bb35-f02030918b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send data to the endpoint\n",
    "def realtime_prediction(predictor, data):\n",
    "    l = len(data)\n",
    "    for i in trange(l):\n",
    "        data_arr = [float(np_float) for np_float in data.iloc[i].values ]\n",
    "        predictions = np.array(predictor.predict(data_arr), dtype=float).squeeze()\n",
    "        print(predictions)\n",
    "\n",
    "def download_from_s3(s3_client, local_file_path, bucket_name, s3_file_path):\n",
    "    try:\n",
    "        # Download the file\n",
    "        s3_client.download_file(bucket_name, s3_file_path, local_file_path)\n",
    "        print(f\"File downloaded successfully to {local_file_path}\")\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            print(\"The object does not exist.\")\n",
    "        else:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "def upload_to_s3(s3_client, local_file_path, bucket_name, s3_file_path=None):\n",
    "    # If S3 file path is not specified, use the basename of the local file\n",
    "    if s3_file_path is None:\n",
    "        s3_file_path = os.path.basename(local_file_path)\n",
    "\n",
    "    try:\n",
    "        # Upload the file\n",
    "        s3_client.upload_file(local_file_path, bucket_name, s3_file_path)\n",
    "        print(f\"File {local_file_path} uploaded successfully to {bucket_name}/{s3_file_path}\")\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        print(f\"ClientError: {e}\")\n",
    "        return False\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file {local_file_path} was not found\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return False\n",
    "        \n",
    "def write_params(s3_client, step_name, params, notebook_param_s3_bucket_prefix):\n",
    "    local_file_path = f\"{step_name}.json\"\n",
    "    with open(local_file_path, \"w\") as f:\n",
    "        f.write(json.dumps(params))\n",
    "    base_local_file_path = os.path.basename(local_file_path)\n",
    "    bucket_name = notebook_param_s3_bucket_prefix.split(\"/\")[2] # Format: s3://<bucket_name>/..\n",
    "    s3_file_path = os.path.join(\"/\".join(notebook_param_s3_bucket_prefix.split(\"/\")[3:]), base_local_file_path)\n",
    "    upload_to_s3(s3_client, local_file_path, bucket_name, s3_file_path)\n",
    "    \n",
    "def read_params(s3_client, notebook_param_s3_bucket_prefix, step_name):\n",
    "    local_file_path = f\"{step_name}.json\"\n",
    "    base_local_file_path = os.path.basename(local_file_path)\n",
    "    bucket_name = notebook_param_s3_bucket_prefix.split(\"/\")[2] # Format: s3://<bucket_name>/..\n",
    "    s3_file_path = os.path.join(\"/\".join(notebook_param_s3_bucket_prefix.split(\"/\")[3:]),  base_local_file_path)\n",
    "    downloaded = download_from_s3(s3_client, local_file_path, bucket_name, s3_file_path)\n",
    "    with open(local_file_path, \"r\") as f:\n",
    "        data = f.read()\n",
    "        params = json.loads(data)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c6395f-943c-403a-a516-9b90ff5535e0",
   "metadata": {},
   "source": [
    "### Generate realtime prediction based on test data\n",
    "In the following cell, we'll run some inferences in realtime using the test data captured in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0958291-d056-4fa7-924f-09f7a6fe7c61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a predictor class for the endpoint\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name, \n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.CSVDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe1df4e-8559-498f-92f0-c11550772396",
   "metadata": {},
   "source": [
    "In [02-preprocess.ipynb](02-preprocess.ipynb) we divided the dataset into training, validation and test dataset. For this lab, we'll use the test dataset for running inferences against the deployed endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eba1f94-fc4b-4f01-955f-edf2bd8b098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_step_name = \"02-preprocess\"\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "notebook_param_s3_bucket_prefix=f\"s3://{bucket_name}/{bucket_prefix}/params\"\n",
    "preprocess_step_params = read_params(s3_client, notebook_param_s3_bucket_prefix, preprocess_step_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685297ca-d9e3-4956-b7dd-85ef3b7425ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_test_x_file_path = \"test_x.csv\"\n",
    "local_test_y_file_path = \"test_y.csv\"\n",
    "s3_test_x_data = preprocess_step_params[\"test_x_data\"]\n",
    "s3_test_y_data = preprocess_step_params[\"test_y_data\"]\n",
    "\n",
    "# Download the test_x.csv and test_y.csv file from S3\n",
    "bucket_name = s3_test_x_data.split(\"/\")[2]\n",
    "s3_test_x_data_key = \"/\".join(s3_test_x_data.split(\"/\")[3:])\n",
    "s3_test_y_data_key = \"/\".join(s3_test_y_data.split(\"/\")[3:])\n",
    "download_from_s3(s3_client, local_test_x_file_path, bucket_name, s3_test_x_data_key)\n",
    "download_from_s3(s3_client, local_test_y_file_path, bucket_name, s3_test_y_data_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d50a74a-da89-442c-8788-6ced63706d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of data vectors from the test dataset sent to the inference endpoint as batch\n",
    "number_of_vectors = 10\n",
    "test_x = pd.read_csv(\"test_x.csv\", header=None).sample(number_of_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9504f-faf7-4072-bc37-0905c258e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the output to see the response payload\n",
    "print(test_x.shape)\n",
    "test_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f1848-94d9-4d23-b66c-3325fec432da",
   "metadata": {},
   "source": [
    "Rename the column names for identifying the feature attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60390899-be22-4720-b24e-aa3c4ef4aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.columns = [f'_c{i}' for i in range(len(test_x.columns))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07523904-416f-44c3-ac4b-7597cac7db7a",
   "metadata": {},
   "source": [
    "Run prediction using the realtime endpoint deployed in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef97f47-f450-4b62-8ed1-e7666845d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "realtime_prediction(predictor, test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf3aaa-ec30-4bb9-9972-206e6de02c5f",
   "metadata": {},
   "source": [
    "# Batch Transform\n",
    "SageMaker offers [batch transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) to optimize inference workloads for the following  scenarios:\n",
    "\n",
    "* Preprocess datasets to remove noise or bias that interferes with training or inference from your dataset.\n",
    "* Get inferences from large datasets.\n",
    "* Run inference when you don't need a persistent endpoint.\n",
    "* Associate input records with inferences to help with the interpretation of results.\n",
    "\n",
    "Functionally, batch transform uses the same mechanics as real-time hosting to generate predictions. It requires a web server that takes in HTTP POST requests a single observation, or mini-batch, at a time. However, unlike real-time hosted endpoints which have persistent hardware (instances stay running until you shut them down), batch transform clusters are torn down when the job completes.\n",
    "\n",
    "To demonstrate the capability, we'll run a batch transform job on the same dataset that we used for realtime inference previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40946cab-65db-4774-91ad-cae8607047e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.inputs import TransformInput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a407b0-1808-4470-851f-e11c866045f9",
   "metadata": {},
   "source": [
    "First we'll get the model_name from the deployed sagemaker endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662428fb-61fb-48e6-929e-a0302ab3fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm.describe_endpoint(\n",
    "    EndpointName=endpoint_name\n",
    ")\n",
    "endpoint_config_name = response[\"EndpointConfigName\"]\n",
    "response = sm.describe_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "model_name = response['ProductionVariants'][0]['ModelName']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57d6225-6b28-4e31-ac60-5eeb7dc95a7e",
   "metadata": {},
   "source": [
    "Define batch_transform variables to use for running a batch tranform job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd8f662-53b9-40a4-8818-406d72b32a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_transform_instance_type = \"ml.m5.large\"\n",
    "batch_transform_output_path = f\"s3://{bucket_name}/{bucket_prefix}/transform\"\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a55073-1bee-45a1-93fa-c86fbb678dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the transform step\n",
    "transformer = Transformer(\n",
    "        model_name=model_name,\n",
    "        instance_type=batch_transform_instance_type,\n",
    "        instance_count=1,\n",
    "        accept=\"text/csv\",\n",
    "        assemble_with=\"Line\",\n",
    "        output_path=batch_transform_output_path,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        base_transform_job_name=f\"player-churn-model-batch-transform\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d6ea6c-32a5-4780-b2e4-789e043ef7a7",
   "metadata": {},
   "source": [
    "Trigger a batch tranform job using the SageMaker python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa19d50-6091-400f-9f41-977257172ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.transform(    \n",
    "        data=s3_test_x_data,\n",
    "        content_type=\"text/csv\",\n",
    "        split_type=\"Line\", \n",
    "        join_source=\"Input\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c099aaf3-3f0e-42d8-83cc-ca6bb14d3e98",
   "metadata": {},
   "source": [
    "Download the inference results from the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12ba181-abb2-4f43-baf5-7fff61a6a261",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $transformer.output_path ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baab355-500f-4bd0-90f5-887c11a0177e",
   "metadata": {},
   "source": [
    "Let's take a look at the payload. The predicted value "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3050ac11-bfe5-4c06-a547-d0c9d81a9f30",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> The results above shows the response payload that contains the input data and the predictions in CSV format. The payload contains both the input and the predicted label. In addition to the default output structure, you can also customize the way batch transform constructs the output. Please refer to this [link](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html#batch-transform-data-processing-examples) to learn more about these customizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7307c5-a234-4fe1-8d32-2c43d804d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -10 test_x.csv.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579140af-5441-47d9-bf54-da9a01b851e6",
   "metadata": {},
   "source": [
    "### Deploy the model version to production\n",
    "Now that we've validated the staging endpoint, assuming we are happy with the results. Next, we'll continue the deployment pipeline to production deployment. \n",
    "\n",
    "Let's construct a CodePipeline approval link. \n",
    "\n",
    "If you used the option 1 `boto3` to create an MLOps project, the `project_name` and `project_id` are set automatically. You can run the following code cell to print the values. If you followed the UI instructions to create a project, you must set the `project_name` manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa30c033-daa8-4ab5-899c-aed5f8f4d9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print(project_name)\n",
    "    print(project_id)\n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"You must set the project_name manually\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29598cf-3c99-440a-886f-6045605d7f97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set to the model deployment project name if you didn't use boto3-based deployment\n",
    "# project_name = \"<USE YOUR PROJECT NAME>\"\n",
    "\n",
    "# Get project id\n",
    "project_id = sm.describe_project(ProjectName=project_name)['ProjectId']\n",
    "\n",
    "# Construct the CodePipline pipeline name\n",
    "code_pipeline_name = f\"sagemaker-{project_name}-{project_id}-modeldeploy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d199ea-5ec0-441a-b58f-be85b9a4788b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "# Show the approval link\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Please approve the manual step in <a target=\"top\" href=\"https://console.aws.amazon.com/codesuite/codepipeline/pipelines/{}/view?region={}\">AWS CodePipeline</a></b>'.format(\n",
    "            code_pipeline_name, region)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e825c8b7-77e4-4929-9b73-396502f9d83a",
   "metadata": {},
   "source": [
    "Click on the link ^^^ above ^^^ to open the CodePipeline console with the pipeline execution workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87e002e-e776-4c73-adcc-5ea79d937579",
   "metadata": {},
   "source": [
    "In the **DeployStaging stage**, choose **Review** on the **ApproveDeployment** step. Note, you might wait until `TestStaging` step completes with `Succeeded` status. \n",
    "\n",
    "![](img/deploy-staging-review.png)\n",
    "\n",
    "In the **Review** dialog box, select **Approve** and choose **Submit**:\n",
    "\n",
    "![](img/approve-deployment.png)\n",
    "\n",
    "Approving the **DeployStaging** stage causes the deployment pipeline to continue and to deploy the model to the production endpoint. To view the endpoints, choose the **Deployments** > **Endpoints** in Studio UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39494560-27a0-49af-92b9-1caafb7c34ae",
   "metadata": {},
   "source": [
    "As your CI/CD deployment pipeline continues, you see the production endpoint in status `Creating` along with the previously deployed staging endpoint in status `InService`:\n",
    "\n",
    "![](img/endpoint-prod-creating.png)\n",
    "\n",
    "After `10-15` min the deployment is completed and both endpoints are in status `InService`.\n",
    "\n",
    "Navigate to the Studio and choose **Deployments** > **Projects**. In the Project pane select `model-deploy-<TIMESTAMP>` project. In the project details pane select **Endpoints**. You see that both endpoints, `staging` and `prod`, are visible in the deployment project because the project and the endpoints are connected via the metadata:\n",
    "\n",
    "![](img/project-endpoints.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477ace97-ba05-44bc-bc36-38df670fafb9",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook you implemented an automated CI/CD deployment pipeline with the following features:\n",
    "- use CloudFormation IaC templates for SageMaker real-time inference endpoint deployment\n",
    "- model approval in the model registry launches the model deployment pipeline\n",
    "- model deployment pipeline contains two stages, staging and production with automated tests for the staging endpoint and manual approval for the production deployment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a45818-0bb7-48b1-bfc6-3c701f6eaa63",
   "metadata": {},
   "source": [
    "## Clean-up\n",
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <p style=\" text-align: center; margin: auto;\">\n",
    "    If you're going to run the step 6 notebook (Data and Model Quality Monitoring), you need to keep at least one of the endpoints. If you finish the workshop here and don't run the step 6 notebook, navigate to the <b>clean-up notebook (99-clean-up.ipynb)</b> and follow the clean-up instructions to avoid charges in your AWS account.\n",
    "    <br>\n",
    "    <br>\n",
    "    You don't need to run the clean-up if you're using an AWS-provided AWS account.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b9d484-5022-4816-8a1b-89e27ffadc66",
   "metadata": {},
   "source": [
    "## Further development ideas for your real-world projects\n",
    "- Add end-to-end data encryption using AWS KMS keys\n",
    "- Create a [custom SageMaker project template](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-templates-custom.html) for model deployment to cover your specific project requirements\n",
    "- Add [multi-account model deployment](https://aws.amazon.com/blogs/machine-learning/multi-account-model-deployment-with-amazon-sagemaker-pipelines/) to your ML workflow\n",
    "- Add automated model tests to the placeholder in the CodePipeline pipeline\n",
    "- Use [Amazon SageMaker Inference Recommender](https://docs.aws.amazon.com/sagemaker/latest/dg/inference-recommender.html) to run automated load tests for your inference endpoints and to select the best instance type and configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed7d41-921d-4174-a177-33c3acc95049",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "- [Deploy a Machine Learning Model to a Real-Time Inference Endpoint](https://aws.amazon.com/getting-started/hands-on/machine-learning-tutorial-deploy-model-to-real-time-inference-endpoint/)\n",
    "- [SageMaker MLOps Project Walkthrough](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-walkthrough.html)\n",
    "- [Amazon SageMaker Pipelines lab in SageMaker Immersion Day](https://catalog.us-east-1.prod.workshops.aws/workshops/63069e26-921c-4ce1-9cc7-dd882ff62575/en-US/lab6)\n",
    "- [Amazon SageMaker secure MLOps](https://github.com/aws-samples/amazon-sagemaker-secure-mlops)\n",
    "- [Testing approaches for Amazon SageMaker ML models](https://aws.amazon.com/blogs/machine-learning/testing-approaches-for-amazon-sagemaker-ml-models/)\n",
    "- [Model hosting patterns in Amazon SageMaker blog series](https://aws.amazon.com/blogs/machine-learning/model-hosting-patterns-in-amazon-sagemaker-part-1-common-design-patterns-for-building-ml-applications-on-amazon-sagemaker/)\n",
    "- [Take advantage of advanced deployment strategies using Amazon SageMaker deployment guardrails](https://aws.amazon.com/blogs/machine-learning/take-advantage-of-advanced-deployment-strategies-using-amazon-sagemaker-deployment-guardrails/)\n",
    "- [MLOps deployment best practices for real-time inference model serving endpoints with Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/mlops-deployment-best-practices-for-real-time-inference-model-serving-endpoints-with-amazon-sagemaker/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca846f6c-3645-493a-a923-7457b2e32a5f",
   "metadata": {},
   "source": [
    "# Shutdown kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e56c7-b568-4208-818c-42634870f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d861de3-ee5a-4c3d-8b8f-04c2523547e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
